{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVj1JpqUWNp1"
   },
   "source": [
    "<h2>CS 4780/5780 Final Project: </h2>\n",
    "<h3>Election Result Prediction for US Counties</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4Y-2-S5WNp1"
   },
   "source": [
    "<h3>Introduction:</h3>\n",
    "\n",
    "<p> The final project is about conducting a real-world machine learning project on your own, with everything that is involved. Unlike in the programming projects 1-5, where we gave you all the scaffolding and you just filled in the blanks, you now start from scratch. The programming project provide templates for how to do this, and the most recent video lectures summarize some of the tricks you will need (e.g. feature normalization, feature construction). So, this final project brings realism to how you will use machine learning in the real world.  </p>\n",
    "\n",
    "The task you will work on is forecasting election results. Economic and sociological factors have been widely used when making predictions on the voting results of US elections. Economic and sociological factors vary a lot among counties in the United States. In addition, as you may observe from the election map of recent elections, neighbor counties show similar patterns in terms of the voting results. In this project you will bring the power of machine learning to make predictions for the county-level election results using Economic and sociological factors and the geographic structure of US counties. </p>\n",
    "<p>\n",
    "\n",
    "<h3>Your Task:</h3>\n",
    "Plase read the project description PDF file carefully and make sure you write your code and answers to all the questions in this Jupyter Notebook. Your answers to the questions are a large portion of your grade for this final project. Please import the packages in this notebook and cite any references you used as mentioned in the project description. You need to print this entire Jupyter Notebook as a PDF file and submit to Gradescope and also submit the ipynb runnable version to Canvas for us to run.\n",
    "\n",
    "<h3>Due Date:</h3>\n",
    "The final project dataset and template jupyter notebook will be due on <strong>December 15th</strong> . Note that <strong>no late submissions will be accepted</strong>  and you cannot use any of your unused slip days before.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdQ0GV-eWNp1"
   },
   "source": [
    "<h2>Part 1: Basics</h2><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFL54oJVWNp1"
   },
   "source": [
    "<h3>1.1 Import:</h3><p>\n",
    "Please import necessary packages to use. Note that learning and using packages are recommended but not required for this project. Some official tutorial for suggested packacges includes:\n",
    "    \n",
    "https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "    \n",
    "https://pytorch.org/tutorials/\n",
    "    \n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mQDt73qwWNp1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# TODO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJGUskA_WNp1"
   },
   "source": [
    "<h3>Weighted Accuracy:</h3><p>\n",
    "Since our dataset labels are heavily biased, you need to use the following function to compute weighted accuracy throughout your training and validation process and we use this for testing on Kaggle.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vz7GtRvuWNp1"
   },
   "outputs": [],
   "source": [
    "def weighted_accuracy(pred, true):\n",
    "    assert(len(pred) == len(true))\n",
    "    num_labels = len(true)\n",
    "    num_pos = sum(true)\n",
    "    num_neg = num_labels - num_pos\n",
    "    frac_pos = num_pos/num_labels\n",
    "    weight_pos = 1/frac_pos\n",
    "    weight_neg = 1/(1-frac_pos)\n",
    "    num_pos_correct = 0\n",
    "    num_neg_correct = 0\n",
    "    for pred_i, true_i in zip(pred, true):\n",
    "        num_pos_correct += (pred_i == true_i and true_i == 1)\n",
    "        num_neg_correct += (pred_i == true_i and true_i == 0)\n",
    "    weighted_accuracy = ((weight_pos * num_pos_correct) \n",
    "                         + (weight_neg * num_neg_correct))/((weight_pos * num_pos) + (weight_neg * num_neg))\n",
    "    return weighted_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4STDPiVFWNp2"
   },
   "source": [
    "<h3>2.1 Preprocessing and Feature Extraction:</h3><p>\n",
    "Given the training dataset and graph information, you need to correctly preprocess the dataset (e.g. feature normalization). For baseline solution in this part, you might not need to introduce extra features to reach the baseline test accuracy.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "xW-Vh-OXNbLh",
    "outputId": "c0adfbb9-9605-403f-feac-d2a9ce031d2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>County</th>\n",
       "      <th>DEM</th>\n",
       "      <th>GOP</th>\n",
       "      <th>MedianIncome</th>\n",
       "      <th>MigraRate</th>\n",
       "      <th>BirthRate</th>\n",
       "      <th>DeathRate</th>\n",
       "      <th>BachelorRate</th>\n",
       "      <th>UnemploymentRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18019</td>\n",
       "      <td>Clark County, IN</td>\n",
       "      <td>18791</td>\n",
       "      <td>30012</td>\n",
       "      <td>51,837</td>\n",
       "      <td>4.9</td>\n",
       "      <td>12.8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6035</td>\n",
       "      <td>Lassen County, CA</td>\n",
       "      <td>2026</td>\n",
       "      <td>6533</td>\n",
       "      <td>49,793</td>\n",
       "      <td>-18.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40081</td>\n",
       "      <td>Lincoln County, OK</td>\n",
       "      <td>2423</td>\n",
       "      <td>10838</td>\n",
       "      <td>44,914</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31153</td>\n",
       "      <td>Sarpy County, NE</td>\n",
       "      <td>27704</td>\n",
       "      <td>44649</td>\n",
       "      <td>74,374</td>\n",
       "      <td>9.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28055</td>\n",
       "      <td>Issaquena County, MS</td>\n",
       "      <td>395</td>\n",
       "      <td>298</td>\n",
       "      <td>26,957</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIPS                County    DEM    GOP MedianIncome  MigraRate  \\\n",
       "0  18019      Clark County, IN  18791  30012       51,837        4.9   \n",
       "1   6035     Lassen County, CA   2026   6533       49,793      -18.4   \n",
       "2  40081    Lincoln County, OK   2423  10838       44,914       -1.3   \n",
       "3  31153      Sarpy County, NE  27704  44649       74,374        9.2   \n",
       "4  28055  Issaquena County, MS    395    298       26,957      -12.8   \n",
       "\n",
       "   BirthRate  DeathRate  BachelorRate  UnemploymentRate  \n",
       "0       12.8       11.0          20.9               4.2  \n",
       "1        9.2        6.3          12.0               6.9  \n",
       "2       11.4       11.7          15.1               5.3  \n",
       "3       14.2        5.0          40.1               2.9  \n",
       "4        9.8        5.3           6.7              14.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may change this but we suggest loading data with the following code and you may need to change\n",
    "# datatypes and do necessary data transformation after loading the raw data to the dataframe.\n",
    "dataset_path = \"./train_2016.csv\"\n",
    "# df = pd.read_csv(dataset_path, sep=',',header=None, encoding='unicode_escape')\n",
    "\n",
    "# Chose to include header to remember column identifiers\n",
    "df = pd.read_csv(dataset_path, sep=',', encoding='unicode_escape')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>County</th>\n",
       "      <th>DEM</th>\n",
       "      <th>GOP</th>\n",
       "      <th>MedianIncome</th>\n",
       "      <th>MigraRate</th>\n",
       "      <th>BirthRate</th>\n",
       "      <th>DeathRate</th>\n",
       "      <th>BachelorRate</th>\n",
       "      <th>UnemploymentRate</th>\n",
       "      <th>state_name</th>\n",
       "      <th>target</th>\n",
       "      <th>float_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18019</td>\n",
       "      <td>Clark County, IN</td>\n",
       "      <td>18791</td>\n",
       "      <td>30012</td>\n",
       "      <td>51837</td>\n",
       "      <td>4.9</td>\n",
       "      <td>12.8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.385038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6035</td>\n",
       "      <td>Lassen County, CA</td>\n",
       "      <td>2026</td>\n",
       "      <td>6533</td>\n",
       "      <td>49793</td>\n",
       "      <td>-18.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40081</td>\n",
       "      <td>Lincoln County, OK</td>\n",
       "      <td>2423</td>\n",
       "      <td>10838</td>\n",
       "      <td>44914</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>OK</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31153</td>\n",
       "      <td>Sarpy County, NE</td>\n",
       "      <td>27704</td>\n",
       "      <td>44649</td>\n",
       "      <td>74374</td>\n",
       "      <td>9.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28055</td>\n",
       "      <td>Issaquena County, MS</td>\n",
       "      <td>395</td>\n",
       "      <td>298</td>\n",
       "      <td>26957</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIPS                County    DEM    GOP  MedianIncome  MigraRate  \\\n",
       "0  18019      Clark County, IN  18791  30012         51837        4.9   \n",
       "1   6035     Lassen County, CA   2026   6533         49793      -18.4   \n",
       "2  40081    Lincoln County, OK   2423  10838         44914       -1.3   \n",
       "3  31153      Sarpy County, NE  27704  44649         74374        9.2   \n",
       "4  28055  Issaquena County, MS    395    298         26957      -12.8   \n",
       "\n",
       "   BirthRate  DeathRate  BachelorRate  UnemploymentRate state_name  target  \\\n",
       "0       12.8       11.0          20.9               4.2         IN       0   \n",
       "1        9.2        6.3          12.0               6.9         CA       0   \n",
       "2       11.4       11.7          15.1               5.3         OK       0   \n",
       "3       14.2        5.0          40.1               2.9         NE       0   \n",
       "4        9.8        5.3           6.7              14.0         MS       1   \n",
       "\n",
       "   float_target  \n",
       "0      0.385038  \n",
       "1      0.236710  \n",
       "2      0.182716  \n",
       "3      0.382901  \n",
       "4      0.569986  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing \n",
    "#extracted state name from country information as a feature\n",
    "get_state_from_county = lambda county : county[county.index(\",\") + 2:] \n",
    "df[\"state_name\"] = df[\"County\"].apply(get_state_from_county)\n",
    "\n",
    "# 0 for GOP, 1 for DEM\n",
    "df[\"target\"] = (df[\"DEM\"] > df[\"GOP\"]).astype(int)\n",
    "df[\"float_target\"] = (df[\"DEM\"] / (df[\"DEM\"] + df[\"GOP\"])).astype(float)\n",
    "\n",
    "#converted median income to int\n",
    "parse_numerical_string = lambda income : int(income.replace(\",\", \"\"))\n",
    "df[\"MedianIncome\"] = df[\"MedianIncome\"].apply(parse_numerical_string)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label columns for whether they is a numerical value, or a non-numerical value for the case of the state name\n",
    "#which will be treated as an index \n",
    "categorical_columns = ['state_name']\n",
    "numerical_columns = ['MedianIncome', 'MigraRate', 'BirthRate', 'DeathRate', 'BachelorRate', 'UnemploymentRate']\n",
    "outputs = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to type category\n",
    "for category in categorical_columns:\n",
    "    dataset[category] = dataset[category].astype('category')\n",
    "statname = dataset['state_name'].cat.codes.values\n",
    "\n",
    "#creates respective tensors for categorical, numerical, and output data\n",
    "categorical_data = np.stack([statname], 1)\n",
    "categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n",
    "\n",
    "numerical_data = np.stack([dataset[col].values for col in numerical_columns], 1)\n",
    "numerical_data = torch.tensor(numerical_data, dtype=torch.float)\n",
    "\n",
    "outputs = torch.tensor(dataset[outputs].values).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(50, 25)]\n"
     ]
    }
   ],
   "source": [
    "#choosing embedding size by the number of unique states divided by 2\n",
    "categorical_column_sizes = [len(dataset[column].cat.categories) for column in categorical_columns]\n",
    "categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set size: 1244, test set size: 311\n",
    "total_records = 1555\n",
    "test_records = int(total_records * .15)\n",
    "\n",
    "#partition training and validation set respectively\n",
    "categorical_train_data = categorical_data[:total_records-test_records]\n",
    "categorical_test_data = categorical_data[total_records-test_records:total_records]\n",
    "numerical_train_data = numerical_data[:total_records-test_records]\n",
    "numerical_test_data = numerical_data[total_records-test_records:total_records]\n",
    "train_outputs = outputs[:total_records-test_records]\n",
    "test_outputs = outputs[total_records-test_records:total_records]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.2 Use At Least Two Training Algorithms from class:</h3><p>\n",
    "You need to use at least two training algorithms from class. You can use your code from previous projects or any packages you imported in part 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, num_numerical_cols, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        #sets up embedding with embedding size for state name\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        #dropout randomly zeros elements to avoid overfitting the training set\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "        #normalizes numerical data per batch \n",
    "        self.batch_norm_num = nn.BatchNorm1d(num_numerical_cols)\n",
    "\n",
    "        #calculates total input size for first layer of the nn\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols + num_numerical_cols\n",
    "\n",
    "        all_layers = []\n",
    "        #each layer has a ReLU activation along with Batch Normalization with dropout\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "        \n",
    "        #finishes with last output layer\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "        #Creates the network\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "        \n",
    "    #forward pass\n",
    "    def forward(self, x_categorical, x_numerical):\n",
    "        #adds embedding for categorical columns\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        #applies batch normalization\n",
    "        x_numerical = self.batch_norm_num(x_numerical)\n",
    "        x = torch.cat([x, x_numerical], 1)\n",
    "        #performs the forward pass calculations\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: -0.06863649\n",
      "epoch:  26 loss: -0.11102536\n",
      "epoch:  51 loss: -0.15216479\n",
      "epoch:  76 loss: -0.22497703\n",
      "epoch: 101 loss: -0.29829210\n",
      "epoch: 126 loss: -0.37059617\n",
      "epoch: 151 loss: -0.54081571\n",
      "epoch: 176 loss: -0.61411351\n",
      "epoch: 201 loss: -0.75948822\n",
      "epoch: 226 loss: -0.93056804\n",
      "epoch: 251 loss: -1.04870176\n",
      "epoch: 276 loss: -1.18483686\n",
      "epoch: 301 loss: -1.28914666\n",
      "epoch: 326 loss: -1.38577700\n",
      "epoch: 351 loss: -1.53217435\n",
      "epoch: 376 loss: -1.67537022\n",
      "epoch: 401 loss: -1.74851191\n",
      "epoch: 426 loss: -1.90516901\n",
      "epoch: 451 loss: -2.00635886\n",
      "epoch: 476 loss: -2.16849065\n",
      "epoch: 501 loss: -2.38289809\n",
      "epoch: 526 loss: -2.49256897\n",
      "epoch: 551 loss: -2.64232898\n",
      "epoch: 576 loss: -2.80099821\n",
      "epoch: 601 loss: -3.03859496\n",
      "epoch: 626 loss: -3.14676261\n",
      "epoch: 651 loss: -3.25770736\n",
      "epoch: 676 loss: -3.34842992\n",
      "epoch: 700 loss: -3.5492279530\n"
     ]
    }
   ],
   "source": [
    "#instantiates the model\n",
    "model = Model(categorical_embedding_sizes, numerical_data.shape[1], 2, [200,100,50,50], p=0.35)\n",
    "#sets CrossEntropyLoss to loss function with weights on the demovrats due to imbalanced data. \n",
    "#CrossEntropy Loss combines a Log Softmax layer with and negative log likelyhood loss in one single class\n",
    "\n",
    "#loss_function = nn.CrossEntropyLoss(weight = torch.Tensor([1.0, 1.1]))\n",
    "loss_function = nn.NLLLoss(weight = torch.Tensor([1.0, 1.1]))\n",
    "\n",
    "#uses Stochastic Gradient Descent, optionally included Nesterov momentum \n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=5e-4, momentum=.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "#number of times to run through the training set\n",
    "epochs = 700\n",
    "\n",
    "#stores losses\n",
    "aggregated_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    \n",
    "    #calculates loss off of model prediction\n",
    "    y_pred = model(categorical_train_data, numerical_train_data)\n",
    "    single_loss = loss_function(y_pred, train_outputs)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    #prints loss\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "    \n",
    "    #backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -3.39637876\n"
     ]
    }
   ],
   "source": [
    "#prints out testing loss\n",
    "with torch.no_grad():\n",
    "    y_val = model(categorical_test_data, numerical_test_data)\n",
    "    loss = loss_function(y_val, test_outputs)\n",
    "print(f'Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8460)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_accuracy(y_output, test_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS 4780 Final Project Student Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
